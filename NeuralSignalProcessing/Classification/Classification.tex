% !TEX TS-program = xelatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the "article" class.
% See "book", "report", "letter" for other types of document.

\documentclass[11pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{fancyhdr}
\usepackage{framed}
\usepackage{amsmath,amsthm,amssymb}

\usepackage{titlesec}

\usepackage[svgnames]{xcolor}

\usepackage{enumerate}

%\usepackage{mathpazo}
\usepackage{mathtools}
\usepackage{unicode-math}
\usepackage{empheq}
\usepackage[most]{tcolorbox}
 

\usepackage{xunicode} %handle unicode
\usepackage{xltxtra} %XeTeX extras
\usepackage{fontspec} %use OTF/TTF fonts


%\newcommand{\lmr}{\fontfamily{lmr}\selectfont} % Latin Modern Roman
%\setmainfont{Myriad Pro} %use this font

\titleformat{\section}
  {\large\bf}{\thesection}{0.25em}{}[\titlerule]
\titlespacing{\section}
  {0pt}{*1.5}{0.25em}

\titleformat{\subsection}
  {\normalfont\bf}{\thesubsection}{0.25em}{}
\titlespacing{\subsection}
  {0pt}{*1}{0.125em}

\renewcommand\thesection{\Alph{section}}

\renewcommand{\labelitemi}{\textemdash}

\DeclareMathOperator{\dif}{d\!}
%\DeclareMathOperator{\Pr}{P}
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\var}{var}
\DeclareMathOperator{\F}{\mathfrak{F}}
\DeclareMathOperator{\Poisson}{Poisson}
\DeclareMathOperator{\Bernoulli}{Bernoulli}
\DeclareMathOperator{\Binomial}{Binomial}
\DeclareMathOperator{\Order}{O}
\DeclareMathOperator{\Uniform}{Uniform}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator{\Tr}{Tr}

\newcommand{\logdet}[1]{\log \left| {#1} \right| }

\newcommand{\xb}{\mathbf{x}}
\newcommand{\ub}{\symbf{\mu}}
\newcommand{\uS}{\symbf{\Sigma}}



\newenvironment{propertybox}{%
   \def\FrameCommand{\colorbox{LightSteelBlue}}%
   \MakeFramed{\advance\hsize-\width \FrameRestore}}
 {\endMakeFramed}

\lhead{\textbf{ELEC548}}
\chead{Review of Classification}
\cfoot{}
\rhead{}
\rfoot{\thepage}
\pagestyle{fancyplain}

\setlength\parindent{0pt}

\begin{document}
\setmainfont{Myriad Pro} %use this font
\setmathfont{Latin Modern Math}
%\setmathfont{TG Pagella Math}

\begin{center}
\large
\textbf{ELEC 548} Byron's Review of Classification
\end{center}

\section{What is Classification}
Classification is a classic instance of \textbf{supervised learning}. The goal is to define a \textbf{classifier} which properly assigns a new data point -- let's call it $\xb$ -- to the appropriate discrete class $C_k \in \lbrace C_1, \ldots, C_K \rbrace$. While there are solutions to classification problems (i.e., nonparametric) which can be posed when the number of classes, $K$, is not known \textit{a priori} or is otherwise unbounded, below we will assume that it not just countable, but also  finite and typically specified as part of the problem statement. Notice that the discrete number of classes is what makes this a \textit{classification} problem --- the machine learning equivalent for continuous data would generally be termed \textit{regression}. 

The process of solving a a classification problem involves two stages: \textbf{Training}  -- optimizing the classifier using labeled training data, and \textbf{Testing} -- evaluating  the performance of the optimized classifier on labeled testing data. Thus, we always divide our labeled data into two: a test data set to evaluate performance and a separate training  data set to ensure that the classifier we have learned generalizes. (Aside - if we didn't do this, what would be the best performing classifier? A lookup table!)  In cases when there are hyperparameters to be optimized -- for example in the model or statistical distribution of the data -- we can split the labeled data into three groups: a training set, a \textbf{validation} data set to pick the best model, and a test set to evaluate final performance.

Classification is a machine learning problem with a wide variety of formulations and solutions. Below, we review classification using \textbf{Probabilistic Generative Models}. For more information as well as a description of other classification approaches, a good resource is \textit{Pattern Recognition and Machine Learning} by Christopher Bishop.

\section{Classification Using Probabilistic Generative Models}
In a classifier built using a probabilisitic generative model, there are two densities for each class $k \in \lbrace 1, \ldots, K\rbrace$:
\begin{itemize}
\item the class-conditional density, $\Pr \left(\xb \mid C_k\right)$ and
\item the class priors $\Pr \left(C_k\right)$
\end{itemize}

To \textbf{train} the classifier, we can use \textit{maximum likelihood parameter estimation}. To use the classifier (i.e., on \textbf{test} data), we chose the class which maximizes the \textit{a posteriori} probability. In other words, we
\begin{itemize}
\item use Bayes' rule to compute $\Pr \left(C_k \mid \xb\right)$
\begin{equation*}
    \begin{split}
        \Pr \left(C_k \mid \xb\right) &= \frac{\Pr\left(\xb \mid C_k\right) \Pr\left(C_k\right)}{\Pr\left(\xb\right)} \\
                    &= \frac{\Pr\left(\xb \mid C_k\right) \Pr\left(C_k\right)}{\sum_{i=1}^{K} \Pr\left(\xb \mid C_i\right) \Pr\left(C_i\right)} 
    \end{split}
\end{equation*}

\item assign $\xb$ to class $C_m$ where
\begin{equation*}
	m = \argmax_k \Pr \left(C_k \mid \xb\right)
 \end{equation*}
\end{itemize}

\subsection{Maximum Likelihood Parameter Estimation}
Once we write down the \textit{training data likelihood}, maximum likelihood parameter estimation is not complicated. What is the data likelihood? Let us assume we are given training data: $\lbrace \xb_n, t_n \rbrace, \quad n = 1, \ldots, N$, where for each of the $N$ training data, $t_n$ is the label for data point $x_n$. Then, the \textit{data likelihood} is just:
\begin{center}
\begin{minipage}{0.75\linewidth}
\begin{propertybox}
    \textbf{Data Likelihood}
    \begin{equation*}
    	\begin{split}
	    	\mathcal{L} &\equiv \Pr \left( \lbrace\xb_n, t_n\rbrace \mid \symbf{\theta} \right)  \\
		 	&= \prod_{i=1}^{N} \sum_{k=1}^K \Pr \left( \xb_n \mid C_k , \symbf{\theta} \right) \Pr \left( t_n = k \mid C_k, \symbf{\theta}\right) \delta(t_n = k)
	\end{split}
    \end{equation*}
    where $\symbf{\theta}$ are the parameters of the densities and $\delta(t_n = k) = 1$ if $t_n = k$ and $0$ otherwise.
\end{propertybox}
\end{minipage}
\end{center}

 
With a probabilistic generative model approach, in general, we will choose the parameters $\symbf{\theta}$ that maximize the data likelihood (maximum likelihood parameter estimation).

\begin{framed}
\subsubsection*{\underline{Example:} Two classes with Gaussian class-conditional density and shared covariance}

\textbf{Training data:} $\lbrace \xb_n, t_n \rbrace, \, n = 1, \ldots, N$ where
\begin{flalign*}
\quad t_n &= 1 \, \text{denotes membership in} \, C_1 \text{and} &\\
\quad t_n &= 0 \, \text{denotes membership in} \, C_2
\end{flalign*}
\begin{flalign*}
\text{Let} \, & \Pr(t_n = 1) = \Pr(C_1) = \pi &\\
 & \Pr(t_n = 0) = \Pr(C_2) = (1- \pi)
 \end{flalign*}

For a data point $\xb_n \in \mathbb{R}^D$, 
\begin{align*}
\Pr(\xb_n, C_1) &= \Pr(\xb_n \mid C_1) \Pr(C_1) = \mathcal{N}(\xb_n \mid \ub_1, \uS) \cdot \pi \\
\Pr(\xb_n, C_2) &= \Pr(\xb_n \mid C_2) \Pr(C_2) = \mathcal{N}(\xb_n \mid \ub_2, \uS) \cdot (1- \pi)  
 \end{align*}

The data likelihood for $N$ data points is then 
\begin{align*}
		\mathcal{L} &\equiv \Pr \left( \lbrace\xb_n, t_n\rbrace \mid \symbf{\theta} \right)  \\
		 	&= \prod_{i=1}^{N} \Big(\mathcal{N}(\xb_n \mid \ub_1, \uS) \cdot \pi\Big)^{t_n} 
			\Big(\mathcal{N}(\xb_n \mid \ub_2, \uS) \cdot \pi\Big)^{1-t_n} \\
		\log \mathcal{L} &= \sum_{i=1}^{N} \Big[   t_n \log \left(\mathcal{N}(\xb_n \mid \ub_1, \uS)\right)  + t_n \log(\pi)  \, +  \\
			& \quad \quad  \quad \quad  (1- t_n) \log \left(\mathcal{N}(\xb_n \mid \ub_2, \uS)\right)  + (1 - t_n) \log(1 - \pi)  \Big]
\end{align*}

where
\begin{align*}
	& \log \left(\mathcal{N}(\xb_n \mid \ub _k, \uS)\right) =  \\ 
		&\quad \quad -\frac{1}{2} (\xb_n  - \ub_k)^T \uS^{-1} (\xb_n  - \ub_k)
		- \frac{1}{2} \logdet{\uS}- \frac{D}{2} \log(2 \pi)
\end{align*}

\subsubsection*{(i) Find $\pi$}
Our goal is to find the value of \pi which maximizes $\mathcal{L}$. Because of the way we've formulated the problem this is
simple calculus - take the gradient and set equal to zero.

\begin{gather*}
	\frac{\partial \log \mathcal{L}}{\partial \pi} = \sum_{n=1}^N \Big[ t_n \cdot \frac{1}{\pi} - (1 - t_n) \cdot \frac{1}{1 - \pi} \Big] = 0 \\
	\frac{1}{\pi} \sum_{n=1}^{N} t_n - \frac{1}{1-\pi} \sum_{n=1}^N (1 - t_n) = 0 \\
	\intertext{Let $N_1 = $ the number of points from $C_1$ in the training data set: $N_1 = \sum_{n=1}^N t_n$, similarly $N_2 = \sum_{n=1}^N (1 -  t_n) = N - N_1$ .}
	\frac{1}{\pi} N_1 - \frac{1}{1-\pi} (N - N_1) = 0 \\
	(1 - \pi) N_1 = \pi (N - N_1)  \\
	\tcboxmath{\pi = \frac{N_1}{N}}
\end{gather*}

What this means is that the maximum likelihood estimate of the class prior probabilities are just the fraction of the training data assigned to each class. 


\subsubsection*{(i) Find $\ub_1$}
 Because of the way we've formulated the problem this is still simple calculus - take the gradient and set equal to zero. 
 If you're not familiar with quadratic forms, take a look at the table of useful matrix calculus identities at the end.

\begin{align*}
	\frac{\partial \log \mathcal{L}}{\partial \ub} &= \frac{\partial}{\partial \ub}  \sum_{i=1}^{N} \Big[   t_n \log \left(\mathcal{N}(\xb_n \mid \ub_1, \uS)\right)  + t_n \log(\pi)  \, +  \\
			 & \quad \quad  \quad \quad  (1- t_n) \log \left(\mathcal{N}(\xb_n \mid \ub_2, \uS)\right)  + (1 - t_n) \log(1 - \pi)  \Big] \\
	\intertext{Keeping only the terms that depend on $\ub_1$:} \\
	&= \frac{\partial}{\partial \ub}  \sum_{i=1}^{N} \Big[   t_n \log \left(\mathcal{N}(\xb_n \mid \ub_1, \uS)\right)   \Big] \\
	&= \frac{\partial}{\partial \ub}  \sum_{i=1}^{N} \Big[   - t_n  \frac{1}{2} (\xb_n  - \ub_1)^T \uS^{-1} (\xb_n  - \ub_1)  \Big] \\
	& = - \sum_{n=1}^{N} \Big(t_n \frac{1}{2}  2  \uS^{-1} (\xb_n - \ub_1) \Big) = 0 \\
	&\implies \uS^{-1} \sum_{n=1}^{N} \Big(t_n  \xb_n  \Big) = \uS^{-1} \Big(  \ub_1  \sum_{n=1}^{N} t_n \Big)
\end{align*}
\begin{equation*}
	\tcboxmath{\ub_1 = \frac{1}{N_1} \sum_{n=1}^N t_n \xb_n} 
\end{equation*}
Similarly, for $\ub_2$:
\begin{equation*}
	\tcboxmath{\ub_2 = \frac{1}{N - N_1} \sum_{n=1}^N (1 - t_n) \xb_n}
\end{equation*}

So what we've shown is that the maximum likelihood estimate of the class means are the sample means of the training data assigned to each class.

\subsubsection*{(i) Find $\uS$}
Keeping only the terms that depend on $\uS$:
\begin{align*}
	\log \mathcal{L} &=  \sum_{i=1}^{N} \Big[   t_n \log \left(\mathcal{N}(\xb_n \mid \ub_1, \uS)\right)   +  (1 - t_n) \log \left(\mathcal{N}(\xb_n \mid \ub_2, \uS)\right) \Big] \\
	& =  \sum_{i=1}^{N} \Big[   - t_n  \Big(\frac{1}{2} (\xb_n  - \ub_1)^T \uS^{-1} (\xb_n  - \ub_1)  - \frac{1}{2} \logdet{\uS} \Big)   \\
	 & \quad \quad \quad  - (1 - t_n)  \Big( \frac{1}{2} (\xb_n  - \ub_2)^T \uS^{-1} (\xb_n  - \ub_2) - \frac{1}{2} \logdet{\uS} \Big)  \Big]  \\
	 & =  \sum_{i=1}^{N} \Big[   -  \frac{t_n }{2} \Big( \Tr \Big(\uS^{-1} (\xb_n  - \ub_1)  (\xb_n  - \ub_1)^T \Big) - \logdet{\uS} \Big)   \\
	 & \quad \quad \quad   - \frac{1 - t_n}{2}  \Big(   \Tr \Big(\uS^{-1} (\xb_n  - \ub_2)  (\xb_n  - \ub_2)^T \Big) - \logdet{\uS} \Big)  \Big]  \\
	\frac{\partial \mathcal{L}}{\partial \uS} &= 	  \sum_{i=1}^{N} \Big[   -  \frac{t_n }{2} \Big( - \uS^{-1} (\xb_n  - \ub_1)  (\xb_n  - \ub_1)^T \uS^{-1}  - \uS^{-1} \Big)   \\
	 & \quad \quad \quad   - \frac{1 - t_n}{2}  \Big(  - \uS^{-1} (\xb_n  - \ub_2)  (\xb_n  - \ub_2)^T \uS^{-1} - \uS^{-1} \Big)  \Big]  \\
	 & = 0 \\
\intertext{If we left and right multiply by $\uS$,} \\
	0 &= \sum_{i=1}^{N} \Big[   \frac{t_n }{2} \Big(  (\xb_n  - \ub_1)  (\xb_n  - \ub_1)^T  - \uS \Big)   +  \frac{1 - t_n}{2}  \Big(  (\xb_n  - \ub_2)  (\xb_n  - \ub_2)^T  - \uS \Big)  \Big] 
 \end{align*}
Note that the labels, $\lbrace t_n\rbrace$ select which of the two terms are actually calculated for each data point. Also getting rid of the $\frac{1}{2}$ terms, we can write this as
\begin{align*}
	0 &= \sum_{n \in C_1} \Big(  (\xb_n  - \ub_1)  (\xb_n  - \ub_1)^T  - \uS \Big)   +  \sum_{n \in C_2}  \Big(  (\xb_n  - \ub_2)  (\xb_n  - \ub_2)^T  - \uS \Big)  \\
	0 &= \sum_{n \in C_1} (\xb_n  - \ub_1)  (\xb_n  - \ub_1)^T  - N_1 \uS  + \sum_{n \in C_2}  (\xb_n  - \ub_2)  (\xb_n  - \ub_2)^T  - N_2 \uS   \\
 \end{align*}
 Thus,
 \begin{equation*}
	\tcboxmath{
	\begin{split}
		\uS &= \frac{N_1}{N} S_1 + \frac{N_2}{N} S_2 , \text{where} \\
		& \quad S_1 = \frac{1}{N_1}  \sum_{n \in C_1} (\xb_n  - \ub_1)  (\xb_n  - \ub_1)^T \\
		& \quad S_2 = \frac{1}{N_1}  \sum_{n \in C_2} (\xb_n  - \ub_2)  (\xb_n  - \ub_2)^T
	\end{split}}
\end{equation*}

So what we've shown is that the maximum likelihood estimate of the shared covariance matrix is a weighted sum of the  sample covariances of each of the classes, where the weighting
is by the fraction of points in each class.  These three results make sense intuitively - absent any other information, the sample estimates of the training data will be the best estimates of
the parameters. 
\end{framed}

\subsection{Test Phase: Assigning a new data point to a class}
Once we have trained our model, we will want to assign data to the best class. As discussed in lecture, aspects of the problem might imply cost/loss functions that would result in biased
assignments. Absent these considerations, the best assignment is the \textit{maximum a posteriori} class.

\begin{center}
\begin{minipage}{0.75\linewidth}
\begin{propertybox}
    \textbf{MAP Assignment}
    \begin{equation*}
    	\begin{split}
		\hat{k} &= \argmax_m \Pr (C_m \mid \xb ) \\
		&= \argmax_m  \frac{\Pr (\xb \mid C_m) \Pr (C_m)}{\Pr (\xb)} \\
		&= \argmax_m \Pr (\xb \mid C_m) \Pr (C_m) \\
		&= \argmax_m \log \Pr (\xb \mid C_m) + \log \Pr (C_m) \\
	\end{split}
    \end{equation*}
\end{propertybox}
\end{minipage}
\end{center}

\begin{framed}
\subsubsection*{\underline{Example cont'd:} Assignment for 2 Gaussians with shared covariance}
For the example of two classes with class-conditional Gaussian densities with a shared covariance matrix, we can further simplify by dropping all the terms which are common
to both classes
\begin{align*}
	\hat{k} &= \argmax_m \; \Pr (C_m \mid \xb ) \\
	&= \argmax_m \; \log \Pr (\xb \mid C_m) + \log \Pr (C_m) \\
	&= \argmax_m \; \ub_m^T \uS^{-1} \xb - \frac{1}{2}\ub_m^T \uS^{-1} \ub_m + \log \Pr (C_m)
\end{align*}

This function creates a decision boundary in $\xb$ space. What does it look like?
\end{framed}


\subsection{Hyperplanes}
A hyperplane is the $D$-dimensional generalization of a line in 2-dimensional space and a plane in 3-dimensional space.

A hyperplane is defined as the set of all $\xb$ such that
\begin{equation*}
	y(\xb) = \mathbf{w}^T \xb + w_0 = 0.
\end{equation*}
Here, $\mathbf{w}$ determines the \textbf{direction} of the hyperplane and $w_0$ determines the offset from the origin. Let's see this in 2-dimensions:

\textbf{Hyperplane Facts:}
\begin{enumerate}
\item $\mathbf{w}$ is \textit{orthogonal} to the hyperplane it defines
\begin{gather*}
	\intertext{Consider two points, $\xb_A$ and $\xb_B$ which lie on a hyperplane.}  \\
	y(\xb_A) = y(\xb_B)  = 0 \\
	\mathbf{w}^T \xb_A + w_0 = \mathbf{w}^T \xb_B + w_0 \\
	\mathbf{w}^T \underbrace{(\xb_A - \xb_B)}_{\mathrlap{\text{a vector lying in the hyperplane}}} = 0 \\
	\implies  \mathbf{w} \; \text{is orthogonal to any vector lying in the hyperplane.}
\end{gather*}

\item The normal distance from the origin to the hyperplane is $\mathbf{w}$ is \textit{orthogonal} to the hyperplane it defines
\begin{gather*}
	\intertext{Let $\xb$ be a point on the hyperplane}  \\
	\implies \mathbf{w}^T \xb + w_0 = 0 \\
	\intertext{The normal distance to the plane is the projection of this (arbitrary vector) $\xb$ onto $\mathbf{w}$} \\
	\bigl( \frac{\mathbf{w}}{\lVert\mathbf{w}\rVert} \bigr)^T \xb  = - \frac{w_0}{\lVert\mathbf{w}\rVert} _{\!\diagup\!\!\diagup}
\end{gather*}

\item The normal distance from any point $\xb$ to the hyperplane is $\frac{y(\xb)}{\lVert \mathbf{w} \rVert}$.
\begin{gather*}
	\intertext{Project $\xb$ onto $\mathbf{w}$, then subtract $\frac{\mathbf{w}}{\lVert\mathbf{w}\rVert}$.}  \\
	\bigl( \frac{\mathbf{w}}{\lVert\mathbf{w}\rVert} \bigr)^T \xb + \frac{\mathbf{w}}{\lVert\mathbf{w}\rVert} = \frac{y(\xb)}{\lVert\mathbf{w}\rVert}_{\!\diagup\!\!\diagup}
\end{gather*}
\end{enumerate}

\end{document}


